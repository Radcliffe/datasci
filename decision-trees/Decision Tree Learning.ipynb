{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Learning\n",
    "\n",
    "We will use an invented dataset to explore decision learning. The dataset contains weather observations for 14 days, and the task is to predict whether the day is good for playing tennis. This example is from [Induction of Decision Trees](http://hunch.net/~coms-4771/quinlan.pdf) by J.R. Quinlan, published in 1986."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('weather.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Write a Python function `freq` to find the relative frequency distribution of an attribute.\n",
    "Hint: Try the `value_counts` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def freq(series):\n",
    "    # TODO: Your code here!\n",
    "    return 0\n",
    "\n",
    "p_temp = freq(df['Temperature'])\n",
    "print(p_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "    mild    0.428571\n",
    "    cool    0.285714\n",
    "    hot     0.285714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "The entropy $H(S)$ of an attribute $S$ is defined by\n",
    "$$H(S) = -\\sum_{i=1}^k p_i \\log_2(p_i)$$\n",
    "where $p_1, \\ldots, p_k$ are the probabilities (relative frequencies) of the values of $S$.\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Write a function `info` that calculates the entropy for a probability distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def info(p):\n",
    "    # TODO: Your code here!\n",
    "    return 0\n",
    "\n",
    "print(info(p_temp)) # Expected answer: 1.\n",
    "# Note: p_temp was calculated in the previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's more convenient to combine `info` and `freq` into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(series):\n",
    "    return info(freq(series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to calculate the entropy of the `Play` attribute. (Answer: 0.94 bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Entropy\n",
    "\n",
    "Let $T$ and $A$ be attributes. The *split entropy* $H(T, A)$ is the weighted average entropy of $T$ when we split on the values of $A$.\n",
    "\n",
    "For example, let's calculate $H(\\text{Play}, \\text{Outlook})$. We split the dataset into groups based on the value of `Outlook`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('Outlook')\n",
    "play = grouped['Play']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the entropy of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = play.aggregate(entropy)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 4 overcast days, 5 rainy days, and 5 sunny days, the split entropy is\n",
    "\n",
    "$$\\frac{4}{14} (0) + \\frac{5}{14} (0.97) + \\frac{5}{14} (0.97) = 0.69$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Write a function to calculate split entropy. You may use the code from the Split Entropy section as a starting point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_entropy(df, T, A):\n",
    "    # TODO: Your code here!\n",
    "    return 0\n",
    "\n",
    "print (split_entropy(df, 'Play', 'Outlook')) # Expected answer: 0.6935361388961919"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "The **Information gain** $IG(T, A)$ is the change in the entropy of $A$ after splitting on $T$. It is defined by\n",
    "\n",
    "$$IG(T, A) = H(T) - H(T, A).$$\n",
    "\n",
    "For example, if we split on the `Outlook` attribute, then the entropy decreases from 0.94 to 0.69, so the information gain is $0.94 - 0.69 = 0.25$.\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "Write a function to calculate information gain. Use the `entropy` and `split_entropy` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(df, T, A):\n",
    "    # TODO: Your code here!\n",
    "    return 0\n",
    "\n",
    "print(information_gain(df, 'Outlook', 'Play')) # Expected answer: 0.246749819774439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which attribute gives the greatest information gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain Ratio\n",
    "\n",
    "The gain ratio is the information gain from splitting on an attribute, divided by the information in the split.\n",
    "The formula is\n",
    "$$GR(T, A) = \\frac{IG(T, A)}{H(T)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Write a function to calculate the gain ratio. Which attribute has the highest gain ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(df, T, A):\n",
    "    # TODO: Your code here!\n",
    "    return 0\n",
    "\n",
    "for attr in ('Outlook', 'Temperature', 'Humidity', 'Windy'):\n",
    "    print('%-15s%f' % (attr, gain_ratio(df, attr, 'Play')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected answers:\n",
    "\n",
    "    Outlook         0.156428\n",
    "    Temperature     0.018773\n",
    "    Humidity        0.151836\n",
    "    Windy           0.048849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees in scikit-learn\n",
    "\n",
    "The decision tree classifier expects the attributes to be numeric, unless I am missing something. The target attribute should assume integer values from 0 to $n-1$, where $n$ is the number of classes.\n",
    "\n",
    "Let's drop the ID column, and recode the other columns as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('ID', axis=1)\n",
    "\n",
    "codes = {\n",
    "    'rainy':  0, 'overcast': 1, 'sunny': 2,\n",
    "    'cool':   0, 'mild':     1, 'hot': 2,\n",
    "    'normal': 0, 'high':     1,\n",
    "    'no':     0, 'yes': 1\n",
    "}\n",
    "\n",
    "df = df.replace(codes)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the decision tree classifier in sklearn to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "X = df.drop('Play', axis=1)\n",
    "y = df['Play']\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on new data\n",
    "\n",
    "Let's create two new days and see what the model predicts. The first day is sunny and mild with normal humidity and calm wind. The second day is rainy and cool with high humidity and high wind. The model predicts that the first day is good for tennis, but the second day is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_days = pd.DataFrame(\n",
    "    [['sunny', 'mild', 'normal', 'no'],\n",
    "     ['rainy', 'cool', 'high', 'yes']]\n",
    ").replace(codes)\n",
    "\n",
    "print(clf.predict(new_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering the decision tree\n",
    "\n",
    "The decision tree can be exported in `dot` format, and rendered using `GraphViz`. Alternatively, the tree can be rendered in Python using the `pydotplus` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=X.columns) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_png(\"decision-tree-entropy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](decision-tree-entropy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
